---
title: "Unit Testing: dogma, intuition, and principles"
date: 2025-01-18 13:57:57
layout: post
lang: en
tags: [software, books, tldr]
draft: true
refs: [clarity, testing]
image: reads/vladimir-khorikov-unit-testing.jpg
---
#+OPTIONS: toc:nil num:nil
#+LANGUAGE: en

** Background
[[https://enterprisecraftsmanship.com/book/][Unit Testing: Principles, Practices, and Patterns]] by Vladimir Khorikov

- how did I learn about the book
  - pragmatism
  - readability?
  - unit of behavior
- i bought it but didn't consider reading it seriously
  - didn't even include it in my list
- because, I had a good idea of what worked and what didn't with testing, been doing it for a decade an a half. probably could pick some good stuff from the book, but I lacked the motivation. there were plenty of other books that seemed a better time investment.

I knew enough to get by.

things changed after recently starting a new job and joining a new team.
the scenario there was different than what I was used to. you see, I had experience in these:
- extending an already effective test suite
- adding tests as part of greenfield project development
- adding tests to an undertested old project
- improving or extending a test suite that team agreed was ineffective

What I hadn't dealt with in the past was a disciplined team, with an extensive but ineffective test suite. What's worse, they didn't quite realise it was ineffective. Unit tests took a lot of effort to write, they didn't catch many bugs, and they broken on small refactors, but that wasn't perceived as a problem.

I had opinions about testing practices and ideas on how to improve this test suite. But they were based on my past experience---ultimately, on subjective intuitions. I would need something better than that to convince the team to change their habits and to justify the effort to my manager.

But before getting into that, what were those intuitions?

** What I thought I knew about testing

- TODO copy list from notebook

(I'm a proud [[https://grugbrain.dev/#grug-on-testing][grug-brained developer]].)

** Dogma, intuition, and principles

- the specific problems I detected in my new project's test suite
- it was obvious I will have to spend time improving the testing approach, either with dedicated tasks or as I worked on other stuff
- reading the unit testing book may equip me with tools to spend the time effectively, to avoid pitfalls that could <discredit> the effort, but, most importantly, it would arm me with justification for the cultural change I wanted to <foster>

the book proved a perfect fit for my intentions, I think mainly because of it's principled approach:
TODO quote introduction to the book


** Commentary

- it aligns with a lot of my intuition, but derives them from core principles (no subjectivity and no dogma)
- it's not dogmatic: it focuses on principles, not in rules, and not in methodologies or tools
- perhaps because of that, it's more a software design than a software testing book. which is interesting: striving for a good test suite is a good way to arrive to a good the system design.
  - a good design is one that lends itself to efficient testing; which isn't the same as code adjusted to be testable.
  - the pursuit of an efficient test suite informs the design of the code; which isn't the same as: the writing of the tests drives the writing of the code.

- TODO consider bringing ch 7 diagrams here, and compare with ousterhout's module depth notion

  #+BEGIN_EXPORT html
<div class="text-center">
 <img src="{{site.config.static_root}}/img/testing1.png">
</div>
#+END_EXPORT

#+BEGIN_EXPORT html
<div class="text-center">
 <img src="{{site.config.static_root}}/img/testing2.png">
</div>
#+END_EXPORT

#+BEGIN_EXPORT html
<div class="text-center">
 <img src="{{site.config.static_root}}/img/deep.png" width="60%">
</div>
#+END_EXPORT


** Highlights

*** Chapter 1: The goal of unit testing
- The goal of testing is to enable /sustainable/ growth of the software project.
- Some tests are valuable and contribute a lot to overall software quality. Others don't. They raise false alarms, don't help you catch regression errors, and are slow and difficult to maintain.
- To enable sustainable project growth, you have to exclusively focus on high-quality tests---those are the only type of tests that are worth keeping in the test suite.
- Coverage metrics are a good negative indicator (low coverage means you're not testing enough) but a bad positive one (high coverage doesn't guarantee good testing quality). Targeting a specific coverage number creates a perverse incentive that goes against the goal of unit testing.

*** Chapter 2: What is a unit test?
- A unit test is an automated test that:
  - verifies a /single unit of behavior/,
  - does it quickly,
  - and does it in isolation /from other tests/.
- Tests shouldn't verify /units of code/. Rather, they should verify /units of behavior/, something that is meaningful for the problem domain and, ideally, something that a business person can recognize as useful. The number of classes it takes to implement such a unit of behavior is irrelevant.
- The ubiquitous use of mocks produces tests that couple too tightly to the implementation.
- Instead of reaching for mocks to test a large, complicated graph of interconnected classes, you should focus on not having such a graph of classes in the first place. More often than not, a large class graph is a result of a code design problem.

*** Chapter 4: The four pillars of a good unit test
- A good unit test has the following four attributes:
  - Protection against regressions
  - Resistance to refactoring
  - Fast feedback
  - Maintainability
- When there is resistance to refactoring, you become confident that your code changes won't lead to regressions. Without such confidence, you will be much more hesitant to refactor and much more likely to leave the code base to deteriorate.
- The more the test is coupled to the implementation details of the system under test (SUT), the more false alarms it generates. You need to make sure the test verifies the end result the SUT delivers: its observable behavior, not the steps it takes to do that.
- Choose black-box testing over white-box testing by default. If you can't trace a test back to a business requirement, it's an indication of the test's brittleness. Either restructure or delete this test.

*** Chapter 5: Mocks and test fragility
- For a piece of code to be part of the system's observable behavior, it has to do one of the following things:
  - Expose an *operation* that helps the client achieve one of its goals.
  - Expose a *state* that helps the client achieve one of its goals.
  Any code that does neither of those two things is an implementation detail.
- Ideally, the system's public API surface should coincide with its observable behavior, and all its implementation details should be hidden from the eyes of the clients. Such a system has a /well-designed/ API. Making the API well-designed automatically improves unit tests.
- The way your system talks to the external world forms the observable behavior of that system as a whole. It's part of the contract your application must hold at all times.
- The use of mocks is beneficial when verifying the communication pattern between your system and external applications. Conversely, using mocks to verify communications between classes inside your system results in tests that couple to implementation details and therefore fall short of the resistance-to-refactoring metric.


*** Chapter 7: Refactoring toward valuable unit tests
- All production code can be categorized along two dimensions:
  - Complexity or domain significance.
  - The number of collaborators.
- This categorization gives us four kinds of code:
  - *Trivial code* (low complexity/significance, few collaborators): this code shouldn't be tested at all
  - *Domain model and algorithms* (high complexity/significance, few collaborators): this code should be unit tested. The resulting unit tests are highly valuable and cheap.
  - *Controllers* (low complexity/significance, many collaborators): controllers should be briefly tested as part of overarching integration tests.
  - *Overcomplicated code*: this code is hard to test, and as such it's better to split it into domain/algorithms and controllers.
- Getting rid of the overcomplicated code and unit testing only the domain model and algorithms is the path to a highly valuable, easily maintainable test suite. With this approach, you won't have 100% test coverage, but you don't need to.
- The domain model encapsulates the business logic and the controller deals with the orchestration of collaborators. You can think of these two responsibilities in terms of /code depth/ versus /code width/. Your code can be either deep (complex or important) or wide (work with many collaborators), but not both.

*** Chapter 8: Why integration testing?
- Check as many of the business scenario's edge cases as possible with unit tests; use integration tests to cover one happy path, as well as any edge cases that can't be covered by unit tests.
- In the most trivial cases, you might have no unit tests whatsoever. Integration tests retain their value even in simple applications.
- Try to always have an explicit, well-known place for the domain model in your code base. The explicit boundary makes it easier to tell the difference between unit and integration tests.
- Layers of indirection negatively affect your ability to reason about the code. This results in a lot of low-value integration tests, that provide insufficient protection against regressions combined with low resistance to refactoring.
  - In most backend systems, you can get away with just three layers: the domain model, application services layer (controllers), and infrastructure layer.
