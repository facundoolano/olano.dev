---
title: From RSS to my Kindle
subtitle: Building website EPUBs with Python
date: 2024-06-01 20:24:33
layout: post
lang: en
tags: [web, projects, programming]
draft: true
excerpt: "A Kindle integration was a natural extension to my feed reader. I had to learn some subtleties to get it working, so it seemed interesting to document the implementation process."
---
#+OPTIONS: toc:nil num:nil
#+LANGUAGE: en

Last year I wrote about [[file:reclaiming-the-web-with-a-personal-reader][how I built feedi]], a personal feed reader, and started using it as my front page to the web. In the months since then I continued to tweak the app, observing my reading habits, experimenting with new features and discarding the ones I didn't need. I now got it to a place where I can count on seeing fresh and interesting content a couple of times a day, and the interface conveniently lets me keep what I plan to read and discard the rest.

But while I'm an avid reader on paper, I struggle with lack of concentration and eye strain when trying to read in a laptop or a desktop monitor ---and it gets worse in the phone screen. In practice, feedi works as a mix of news feed and content finder and organizer; I prefer to send longer blog posts or essays to my Kindle so I can get back to them when I'm offline in bed, in the bathroom, at a cafe or on the bus.

So a Kindle integration was a natural extension to feedi. Not only because it streamlined my reading workflow but because the official Amazon Send To Kindle extension does a poor job of extracting  content from most websites. I was already using Mozilla's [[https://github.com/mozilla/readability][readability library]] to embed cleaned up HTML content in the reader, so I just needed to figure out how to send those articles over to my Kindle. I learned a couple of things along the way, so it seemed interesting to document the implementation process here.

-----

My first instinct was trying to get away with a Kindle integration that didn't require sending emails from my app. I found a [[https://github.com/maxdjohnson/stkclient][Python library]] that "impersonated" an Amazon client and wrote my first implementation around it, but it turned out to be brittle: it required storing device credentials in the reader app and manually authenticating every few days, which hurt the user experience, ultimately discouraging me from using the feature at all.

So a few months later I took another stab at it using the more reasonable option of sending articles as EPUB email attachments. At high-level, this is what the app needed to do:

#+begin_src python
# feedi/routes.py

import flask

from flask import current_app as app
from flask_login import current_user, login_required

@app.post("/entries/kindle")
@login_required
def send_to_kindle():
    url = flask.request.args['url']
    article = scraping.extract(url)
    attach_data = scraping.package_epub(url, article)
    email.send(current_user.kindle_email, attach_data, filename=article['title'])
    return '', 204
#+end_src

Fetch the HTML from the website, extract the article content from it, package it into an EPUB file, send it as the attachment to an email to the Kindle device. Let's look at each of these steps in turn.

For the extraction I tried every Python library I could find[fn:1], but none seemed to do as good of a job as Firefox's reader view, so I decided to use the [[https://github.com/mozilla/readability][JavaScript library]] that powers it through a little Node.js script:

#+begin_src javascript
#!/usr/bin/env node

const { JSDOM } = require("jsdom");
const { Readability } = require('@mozilla/readability');

const url = process.argv[2];

JSDOM.fromURL(url).then(function (dom) {
  let reader = new Readability(dom.window.document);
  let article = reader.parse();
  process.stdout.write(JSON.stringify(article), process.exit);
});
#+end_src

The script's output look like this:
#+begin_src json
{
  "title": "From RSS to my Kindle",
  "byline": "Facundo Olano",
  "dir": null,
  "lang": null,
  "content": "<div id=\"readability-page-1\" class=\"page\"><div lang=\"en\"><header><h3>Building website EPUBs with Python</h3></header><p>Last year I wrote about <a href=\"https://olano.dev/blog/reclaiming-the-web-with-a-personal-reader\">how I built feedi</a>, a personal feed reader, and started using it as my front page to the web. (...)",
  "textContent": "Building website EPUBs with Python\n\nLast year I wrote about how I built feedi, a personal feed reader, and started using it as my front page to the web. (...)",
  "length": 2793,
  "excerpt": "A Kindle integration was a natural extension to my feed reader. I had to learn some subtleties to get it working, so it seemed interesting to document the implementation process.",
  "siteName": "olano.dev"
}
#+end_src

And this is how I call it from Python:
#+begin_src python
# feedi/scraping.py
import json
import subprocess

def extract(url):
    r = subprocess.run(["feedi/extract_article.js", url],
                       capture_output=True, text=True, check=True)

    article = json.loads(r.stdout)
    return article
#+end_src

I found that some websites rely on JavaScript to load images lazily, so I tweaked the tags to force image rendering (both in the app and in Kindle):

#+begin_src diff
 import json
 import subprocess

+from bs4 import BeautifulSoup

 def extract_article(url):
     r = subprocess.run(["feedi/extract_article.js", url],
                        capture_output=True, text=True, check=True)

     article = json.loads(r.stdout)

+    # load lazy images by setting data-src into src
+    soup = BeautifulSoup(article['content'], 'lxml')
+    LAZY_DATA_ATTRS = ['data-src', 'data-lazy-src', 'data-srcset',
+                       'data-td-src-property']
+    for data_attr in LAZY_DATA_ATTRS:
+        for img in soup.findAll('img', attrs={data_attr: True}):
+            img.attrs = {'src': img[data_attr]}
+
+    article['content'] = str(soup)

     return article
#+end_src

The bulk of the work was putting together a valid EPUB file from this website content. With a very superficial research I found that EPUB files are just zips with a few metadata files. So I started by zipping the article that the extraction script gave me:

#+begin_src python
# feedi/scraping.py
import io
import zipfile

def package_epub(url, article):
    output_buffer = io.BytesIO()
    with zipfile.ZipFile(output_buffer, 'w', compression=zipfile.ZIP_DEFLATED) as zip:
        zip.writestr('article.html', article['content'])

    return output_buffer.getvalue()
#+end_src

Based on [[https://github.com/thansen0/sample-epub-minimal][this sample repository]] I added mimetype, container and content files pointing to the single article.html file:

#+begin_src  python
zip.writestr('mimetype', "application/epub+zip")
zip.writestr('META-INF/container.xml', """<?xml version="1.0"?>
<container version="1.0" xmlns="urn:oasis:names:tc:opendocument:xmlns:container">
<rootfiles>
<rootfile full-path="content.opf" media-type="application/oebps-package+xml"/>
</rootfiles>
</container>""")

author = article['byline'] or article['siteName']
if not author:
    # if no explicit author in the website, use the domain
    author = urllib.parse.urlparse(url).netloc.replace('www.', '')

zip.writestr('content.opf', f"""<?xml version="1.0" encoding="UTF-8"?>
<package xmlns="http://www.idpf.org/2007/opf" version="3.0" xml:lang="en" unique-identifier="uid" prefix="cc: http://creativecommons.org/ns#">
<metadata xmlns:dc="http://purl.org/dc/elements/1.1/">
<dc:title id="title">{article['title']}</dc:title>
<dc:creator>{author}</dc:creator>
<dc:language>{article.get('lang', '')}</dc:language>
</metadata>
<manifest>
<item id="article" href="article.html" media-type="text/html" />
</manifest>
<spine toc="ncx">
<itemref idref="article" />
</spine>
</package>""")
#+end_src

This was enough to get the text working, but I needed to download and zip the article images if wanted them to show in the Kindle:

#+begin_src diff
 import io
 import zipfile

+from bs4 import BeautifulSoup

 def package_epub(url, article):
     output_buffer = io.BytesIO()
     with zipfile.ZipFile(output_buffer, 'w', compression=zipfile.ZIP_DEFLATED) as zip:
-        zip.writestr('article.html', article['content'])
+        soup = BeautifulSoup(article['content'], 'lxml')
+        for img in soup.findAll('img'):
+            img_url = img['src']
+            img_filename = 'article_files/' + img['src'].split('/')[-1].split('?')[0]
+
+            # update each img src url to point to the local copy of the file
+            img['src'] = img_filename
+
+            # download the image and save into the files subdir of the zip
+            response = requests.get(img_url)
+            if not response.ok:
+                continue
+            zip.writestr(img_filename, response.content)
+
+        zip.writestr('article.html', str(soup))
     return output_buffer.getvalue()
#+end_src
Note how I also had to rewrite the ~<img>~ tags so the source pointed to the local files location instead of the public internet ones (much like the browser does when downloading a page). Since the Kindle can't render WebP images, my next step was to convert those to jpegs:

#+begin_src diff
 import io
 import zipfile

 from bs4 import BeautifulSoup
+from PIL import Image

 def package_epub(url, article):
     output_buffer = io.BytesIO()
     with zipfile.ZipFile(output_buffer, 'w', compression=zipfile.ZIP_DEFLATED) as zip:
         soup = BeautifulSoup(article['content'], 'lxml')
         for img in soup.findAll('img'):
             img_url = img['src']
             img_filename = 'article_files/' + img['src'].split('/')[-1].split('?')[0]
+            img_filename = img_filename.replace('.webp', '.jpg')

             # update each img src url to point to the local copy of the file
             img['src'] = img_filename

             # download the image and save into the files subdir of the zip
             response = requests.get(img_url)
             if not response.ok:
                 continue

-            zip.writestr(img_filename, response.content)
+            with zip.open(img_filename, 'w') as dest_file:
+                if img_url.endswith('.webp'):
+                    jpg_img = Image.open(io.BytesIO(response.content)).convert("RGB")
+                    jpg_img.save(dest_file, "JPEG")
+                else:
+                    dest_file.write(response.content)

         zip.writestr('article.html', str(soup))
#+end_src

Now I just needed to email this zip file. I didn't want to depend on a paying service and remembered from my old web developer days that a regular Gmail account was the cheap option to send a low volume of emails from an app. Things had changed slightly since the last time I tried this, though: I had to enable two-factor authentication and generate an "app password" (at ~https://myaccount.google.com/apppasswords~) for Google to accept my SMTP requests.

This is what the email boilerplate looked like:

#+begin_src python
# feedi/email.py
import smtplib
import urllib.parse
from email import encoders
from email.mime.base import MIMEBase
from email.mime.multipart import MIMEMultipart

def send(recipient, attach_data, filename):
    server = "smtp.gmail.com"
    port = 587
    sender = "my.reader.email@gmail.com"
    password = "some gmail app pass"

    msg = MIMEMultipart()
    msg['From'] = sender
    msg['To'] = recipient
    msg['Subject'] = f'feedi - {filename}'
#+end_src

The ~attach_data~ being the epub zip bytes. The Kindle uses the filename from the ~Content-Disposition~ header as the title displayed in the device library. This is a problem when the title contains spaces or non-ASCII characters ---as is the case for articles in Spanish. I got that working after a few tries with the escaping syntax suggested by this [[https://stackoverflow.com/questions/93551/how-to-encode-the-filename-parameter-of-content-disposition-header-in-http/216777#216777][StackOverflow answer]]:

#+begin_src  python
part = MIMEBase('application', 'epub')
part.set_payload(attach_data)
encoders.encode_base64(part)

filename = urllib.parse.quote(filename)
part.add_header('Content-Disposition', f"attachment; filename*=UTF-8''{filename}.epub")
msg.attach(part)
#+end_src

Finally, the email is sent like this:
#+begin_src python
smtp = smtplib.SMTP(server, port)
smtp.ehlo()
smtp.starttls()
smtp.login(sender, password)
smtp.sendmail(sender, recipient, msg.as_string())
smtp.quit()
#+end_src

Of course, for the Kindle to accept these emails, I had to whitelist the reader email address in my Amazon device settings.

-----
- <this is working well enough, but there are a few things I wish I had>


- Some websites regrettably rely on JavaScript to load their HTML content, which is obviously not picked up by the readability package. I experimented with a headless browser to fetch the content, but that made the app slow and brittle, so I just choose to not read content from JavaScript-centric websites. (I apply a similar rule to paywalls).



  - ff extension to send articles outside feedi, through feedi
  - share target, which unfortunately doesn't work for progressive web apps in iOS. the alternative of building a safari extension is expensive and way too much work

** Notes

[fn:1] [[https://github.com/codelucas/newspaper][newspaper3k]], [[https://github.com/fhamborg/news-please][news-please]], [[https://github.com/goose3/goose3][goose3]], [[https://github.com/adbar/trafilatura][trafilatura]], [[https://github.com/alan-turing-institute/ReadabiliPy][ReadabiliPy]], [[https://github.com/buriy/python-readability][python-readability]].
