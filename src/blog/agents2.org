---
title: Another round of building with agents
date: 2025-12-13T11:59:38-03:00
layout: post
lang: en
tags: [ai, projects]
draft: true
---
#+OPTIONS: toc:nil num:nil
#+LANGUAGE: en

Previously on /Facundo's Adventures with LLMs/:

- [[https://jorge.olano.dev/blog/on-ai-assistance/][On AI assistance]]
- [[augmentation-replacement][Augmentation / Replacement]]
- [[agentic-coding-experience][Quick notes on a brief agentic coding experience]]

This time I will document a successful experience I had building a small web app almost exclusively with Claude Code.

My previous attempt had made me sick, this time I felt empowered. What changed?

** Part 1: context

These first few sections just provide context about the project; jump to the second part for a discussion and my take-aways of building with agents.

*** The project
<GiraLibros.com is a small book trading web application for the Buenos Aires local area.
- after signing up, users publish a list of books they offer for exchanging, and get to browse other user's offered books.
- When a users sees a book they like, they send an exchange request to the owner
- An exchange request is just an email notification with the list of books offered by the interested user.
- If the user that receives the request is interested in any of the other user's book, they get in touch a their convenience and trade books. Most of this happens outside of the application (there are no incentives in keeping users inside the app, and email or WhatsApp work much better for coordinating an exchange)

*** Motivation
This wasn't an original idea, there is an app that works exactly like that in Argentina, which worked pretty well for a few years. Unfortunately the owners of that app recently imposed a very aggressive subscription where unsubscribed free users can barely use the app anymore.
As a side effect, even if you pay the subscription, most of the other users don't so it's hard to make an exchange. This ultimately made the community stagnate.

The idea of my project was to restore that community by guaranteeing an unlimited free experience. Since I'm not out to make money from this, it's implied that I wanted to design to minimize the cost of maintaining it if it takes off.

*** Goals
- Finishing the project, with the exact UX I was going for (which was very simple anyway)
- Minimizing my effort (including frustration and disgust with the tools)
- Minimizing operational costs to run the system
- Having a decent understanding of the codebase (at least the backend part)

*** Non-goals
- Learning
- Having fun
- Producing a flexible or extensible system
- Maximizing maintainability
- Strong ownership over the codebase
- Making users happy (TODO explain)
- Building a successful product (that is, I wouldn't consider the project a failure if I couldn't get people to use it)

While all the things in this second list are desirable, I was willing to trade them off for those in the first list.

*** Stack
- django:
  - used to be my bread and butter 10 years ago until I moved out of python and traditional web development.
  - most recently, for one reason or another, I've been using flask and sqlalchemy, occassionally trying HTMX for fancier UIs
  - but recently grew convinced that the simplicity of Django + vanilla js is hard to be beat for web apps with unpretentious interfaces. so while I think go makes my live easier to deploy and operate a system, I knew that django would maximize my productivity. for the deploy part I would just replicate I'd been doing with my other projects (linux vps, nginx, gunicorn, sqlite, bulma for css)

*** Claude Code

- the combination of goals, non goals, and tooling made this an ideal candidate for coding with agents.

- I suppose CC got a lot better in the few months since I first tried, but truth be told the bigger factors were that:
  - I learn through colleagues about the 20usd suscription (as opposed of the 100/200usd one and the crazy spend of the API key alternative)
  - I kept reading experiences from other (often skeptical) devs which gave me ideas to approach the use of the tool differently

- note that I used django intensively for 5 years... a decade ago. that made it an interesting fit, because I still have a good grasp of django concepts, a notion what's doable with it, what's builtin and what should be ad hoc, etc., but I completely forgot the syntax and the little details. I could instruct claude precisely what to do, saving me from a lot of documentation roundtrips, while still catching when it tried to bullshit me into getting creative ore reinventing the wheel
- similarly I have an idea of what was supported by bulma, and I could delegate the HTML layout and css to claude
- this will be a clear trade off, I'm a backend dev, I knew I wouldn't be as effective in catching the garbage early on when it came to CSS structure and javascript features, but to be honest I'm not very good at building maintainable interfaces on my own anyway, and it's by far the biggest burden on me for this kind of project, so I was more than willing to make sacrifices on this front.


- I should note that using agents wasn't a fundamental factor in this project: I first made my mind about doing it, then decided to see how far I could go with CC. Had I had a first few unproductive sessions I would start from scratch writing all the code myself. (perhaps running a higher risk of dropping the project before completion)

*** Result
- released working mvp in 1 (part time) week
- added QoL improvements in another week
- got ~70 users and ~300 books after promoting it
- cost of running it is
  X/month hetzner vps
  X/year porkbun domain
  X/6 months for zepto emails
  ~ the cost a used book in Buenos Aires.

** Part 2: process + lessons learned
*** CHOP not vibe
- link to recent article
https://diwank.space/field-notes-from-shipping-real-code-with-claude


- my own flavor of CHOP went like this:
  - not only claude doesn't get to do PRs or PR reviews: it doesn't even get to do commits.
  - I typically either provide some product-level context upfront and then either provide or iterate with Claude on a succinct TODO list of the tasks to be done before letting it start coding. the idea is to minimize the opportunities for it to get creative.

(as stated before, the goal here is not maximize velocity but to get a finished product with minimal effort and frustration on my side.
I have a lot of training in high level task breakdown, superficial reviewing, foreseeing pitfalls, and building confidence through a test suite, so this approach turns out to be very effective for my purposes.)

*** Agent customization
  - don't invest on its tooling: no sophisticated CLAUDE.md, no MCP, no custom commands, no system prompts, no skills, no plugins. I'm not saying these aren't important, but in my previous experience I found them to be non-conducive rabbit holes: I ended up spending a lot of tokens trying to come up with an ideal workflow specification; this is especially problematic because the agent is not trained with knowledge about itself, so it's very ineffective at configuring itself. In that context, it would requires a lot mental effort on my side to tune the agent to my satisfaction, and in my opinion, spending mental effort in such meta-tasks defeats the purpose of using agents in the first place, at least in the context of such a short lived hobby project. Additionally, with these beasts any setup seems to go stale every few months, so my attitude was: see how far this can get me now with minimal tweaking; if that's not very far I'll just wait and try again in a few months.

*** Work sessions
- the only thing I found to be fundamental is to follow X advice to turn compaction off. If you reach compaction then that session is dead. And also if you near compaction you'll likely kill any remaining tokens you have in your current session. These constraints made me arrange my work to always be approachable in one session:
  - don't try to do too much at once
  - close and reopen claude as a sort of "checkpointing" when I'm done with a feature and want to start another one.
  - do a plan-only session, with a detailed markdown plan as output for work that seems to complex work on start to finish before running out of context token or session usage limits.

- I find that these restriction to work on self contained sessions, and the need to take breaks when reaching both session and weekly limit made me keep my work organized and avoid the agent subtly dragging me into its spirals of nonsensical coding sprees.

- When I ran out of tokens, since there was still that barrier on familiarizing with the code, I opted to make progress on UX ideas, feature specifications, test stubs and server setup---all pieces that I didn't want the AI to touch. I found this context switching useful to make steady progress.

In a more serious or time-constrained scenario, I would still opt for paying two 20 dollar pro plans instead of a 100 or 200 USD max plan. I haven't tried, but I suspect a combination of Claude Code Pro and Codex Plus is the ideal combination.

*** Testing
I mostly agree the sacred rule on this post
https://diwank.space/field-notes-from-shipping-real-code-with-claude

but I slightly adapted to reduce friction in adding new tests.
- I don't let AI come up with their own tests
- I have specific rules about what I look for in a test (which aren't different from non-ai driven projects). basically what I listed here and discussed in more length here: test units of behavior not units of code, don't couple to implementation details, prefer integration tests over smaller scale unit tests, don't mock intermediate layers (just the inputs and outputs of your system), don't access the DB directly. (I made claude read those and include the rules in its CLAUDE.md)

This is one of the few areas where I hold my opinions strongly. Taking this approach helps me trust my codebase even when I don't fully understand it or there are pieces that I know need improvement. I find an explicit test exercising every relevant business rule beats documentation, comments and the overall design/architecture in providing guarantees that the system does what it needs to do and will continue to over time.

This becomes even more important in the context of agentic coding, where I'm voluntarily resigning control and understanding of the implementation.

- the slight adjustment is that I want to test as much as possible, and writing tests line by line is still burdensome. So I typically write outlines like:
  [Example]
then ask Claude to implement one at a time and I closely review to make sure it's following my rules and not overcomplicating the implementation. after a few are implemented then it's less likely to deviate from the sorrounding style.
I don't let Claude add tests before adding my detailed outline first

I also do a manual smoke testing after each feature is ready to merge. <I haven't experimented with something like playwright yet, but I suspect that would be a better approach to catch UI regressions, where a lot of the complexity of the app resides

*** Don't repeat yourself

Code duplication is an interesting thing to reflect about in the context of working with agents. LLMs are paid (?) to output tokens, so unsurprisingly Claude Code indulges in all kinds of duplication, <not only pieces of code already defined elsewhere in the project (and possibly outside of its current context), but pieces defined right above the code its adding, or in a class its sub-classing, in the django built-ins already imported, etc.

It's tempting to add rigid rules to CLAUDE.md to prevent code duplication, but as we collectively learned in the last decade, dogmatically removing all code duplication tends to do more harm than good.

The anniversary edition of /The Pragmatic Programmer/ makes a useful distinction between duplication /of code/ and duplication /of knowledge/. The latter being what we need to strictly remove. <The situation compounds in the context of coding agents, where (re)writing code is effortless but scattered knowledge is the biggest system risk.

So I found most of my reviews deal with strategically removing or allowing duplication: if it's knowledge it needs to be centralized and I need to think carefully how, if it's just code I can instruct how to extract and reuse, but more often than not it's OK just live with that duplication.

[TODO better examples?]

*** Debugging

** Conclusions

- previous attempt I qualified the feeling as "exhilarating recklessness" and compared the experience with going to the casino.
- this time instead I felt like I was leveraging my experience: like I had been saving in experience for 15 years and Claude allowed me to "spend" some of that experience to get something that I wanted. This analogy works in more than one way:
  - it felt rewarding to see how much I know about this stuff that I had not think about in a long while, how many little nuances about putting together a web app and trying different user interfaces I could think about, how many problems I could catch by just reviewing Claude's code. Even if wasn't writing the code, there was a lot I could bring to the table .
  - I did feel like if I only coded this way my experience would give diminishing returns and my skills would atrophy

- I'm sure there are many mistakes I made by letting claude do the work for me, but this was clearly a successful project given my goals and the results
- I still don't think it would be wise to use this a lot in professional environments, other than for proof of concept-type of software. I don't think that trading short term productivity for long term ownership and knowledge building makes sense in most cases.
