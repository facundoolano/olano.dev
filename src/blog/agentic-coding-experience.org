---
title: Quick notes on a brief agentic coding experience
date: 2025-06-16 14:50:19
layout: post
lang: en
tags: [ai]
draft: true
---
#+OPTIONS: toc:nil num:nil
#+LANGUAGE: en

1. Perhaps not advisable from a metal health perspective, but I have my RSS reader set up to fetch top stories from Hacker News and lobste.rs. This means every morning I get a fresh batch of AI-related blog posts delivered to my feed.
2. I continue to feel ambiguous about this topic and I continue to enjoy reading all but the maximalist takes on either side of the fence. I like to see how people are trying and failing to get a benefit from these tools, and how people are investing in their setup and getting something remarkable out of them. I particularly liked a couple of recent stories: [[https://lucumr.pocoo.org/2025/6/12/agentic-coding/][Agentic Coding Recommendations]] and [[https://diwank.space/field-notes-from-shipping-real-code-with-claude][Field Notes From Shipping Real Code With Claude]].
3. What I liked about these is that the authors don't deny the limitations of the tech, they don't pretend that everything magically works out of the box, and they give practical recommendations to set these up. I especially appreciate the "never let AI write your tests" from the second link. I imagine it's not the only way to go about it, but this resonates with my own non-AI experience. I can relate to putting a lot of effort on getting the tests just right so they become insurance against code that I can't entirely trust. I can see Agentic coding as an exacerbation of this scenario.
4. Before this I had been using LLMs almost exclusively in chat sessions inside Emacs through gptel. First ChatGPT then Claude. After reading the linked stories I decided to give Claude Code a try using my personal feed reader as a playground, trying to task the LLM to tackle a bunch of little bug fixes, refactors, and features I been filing while I use the app, but didn't really plan to tackle any time soon. Here's the resulting raw, stream-of-conscious bullet list brain dump.
5. I can summarize my experience like this: exhilarating and irresponsible. Kind of like going to the casino. Addictively fun, but you can lose your house if you don't pay attention.
6. Just like with my first experiences with LLMs, it's the interface what I'm most impressed about. It's how the tool can interact with shell commands and learn about them, and how I can conversationally help it learn new tricks and adapt its workflow to my preferences. Claude sonnet is just as knowledgeable and dumb and sloppy as in the chat buffer, but the fact that it can access my project, do trial an error on its own, and rely on any tool I give it access to, makes up for a good chunk of its limitations.
7. I can't really say that I was more productive in terms of time, let alone quality, that if I was tackling the same tasks manually in my editor. I mean if I really had to, if this was real work. But the thing is that this is a side project and these are features that I have been specifically putting off, and the fun I was having with the agent was the kick I needed to get them done. What's most important is that the part of my brain that I needed to engage in the process was completely different: I didn't need to concentrate nearly as much, even while I was carefully reviewing the code, I wouldn't get as tired, and I wouldn't feel like I was working on my free time.
8. I must clarify that I wasn't /vibecoding/, I'm not interested in entirely letting go of my codebase like that. I wanted to guide and let the agent do its thing but then I'd review the result before merging it back to the main branch, because I had expectations to continue using the app, I wanted to be able to still understand and extend the code myself when necessary, and I wasn't getting evidence that I could trust the agent to do the reasonable thing most of the time.
9. The agent needs /a lot/ of babysitting and guard railing, which is kind of what I expected going in. I could perhaps improve the experience if I was willing to make a bigger investment in the process---curating my CLAUDE.md, writing better tools, tuning my workflow. By which I'd be surely out of magic productivity land and onto deliberate tool building. Which is fine, it would be worthwhile and even fun to do if it wasn't that this thing is so ridiculously expensive.
10. <Because the elephant in the room, the showstopper problem was the amount of money I needed to pour into this to keep it going. I worked for a couple of half-day sessions, maybe 4-6 hours in total, and spent about 30 dollars to get a couple of trivial code edits and a half-broken simple feature.
11. Some people would say this is cheap if you compare it to a typical programmer's salary instead of a typical software subscription, a comparison I'm not willing to make. And maybe the monthly subscription is more cost-effective than the pay-as-you-go model---I didn't really do the math. But this is not a work tool I'm paying for; it's a dopamine fix. Like a slot machine, I was pouring money in one end just to see what came out on the other. This is fun but also makes me sick and feels wrong.
12. Ultimately, this mode of working felt irresponsible because I could witness, real-time, how I was being estranged from my own project. I've seen it happen on one of my first open-source projects. After a few years I lost interest in it and let the community take over, limiting myself to review external contributions. <Since I don't care personally about it much, I would accept most seemingly working contributions. By know I don't really understand it's structure anymore and I couldn't update myself without a big re-learning effort. LLM agents could catalyze this estrangement process of year to a week or two.>
13. There's more to it. You can always re-learn a strange project, no matter how badly shaped it is. <I resurrected a few  haunted-forest projects in my career---progressively understanding and recovering ownership of the codebase, entirely rewriting it line-by-line, never indulging in the lazy rewrite from scratch---and my experience is, for all of the mud that can accumulate over years of careless maintenance, if you know how to look, you can always find traces of intent, you can infer the presence, the needs and constraints of many previous maintainers. And that you can use to put back parts of the puzzle together, to gain understanding and confidence and to guide some of your decisions. This is not the case, I bet, with LLM-generated code. With LLMs it's all  random text generation, plausible nonsense, statistical intent. I don't think there's coming back from that kind of surrender, from such kind of death.
14. If Claude Code was cheaper I think I could have a good kick out of it for certain low-stakes projects. Not work but play. I don't think I could bring myself to program like this professionally, though. At least the current state of the art feels incompatible with my duties as a software designer.
